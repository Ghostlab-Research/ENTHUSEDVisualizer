{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf24f320",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is the better-organized version of the pipeline for turning data from SimpleLogger.cs into csv files which the DEPTH visualizer can use in Unity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2c6fa",
   "metadata": {},
   "source": [
    "# Section 1: Put Everything Into One Big Data Frame\n",
    "\n",
    "Process File takes a position csv and an interaction csv and returns a single data frame with all of the information you need, for addition to The Big Data Frame (combined_df). This function will not work with data produced by SimpleLogger.cs, because SimpleLogger.cs uses a slightly different format. The changes required for compatability with data produced by SimpleLogger shouldn't be huge, but some of the hard-coded numbers will not correspond to the correct column anymore. \n",
    "\n",
    "simplfy_df should remap that giant data from into a dataframe that contains only what you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41d1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(positions_file, interactions_file, participant_number):\n",
    "    positions = pd.read_csv(positions_file)\n",
    "    interactions = pd.read_csv(interactions_file)\n",
    "    \n",
    "    # Add participant number to the positions DataFrame\n",
    "    positions['participantNumber'] = participant_number\n",
    "    \n",
    "    #get just the interactions where we're going to the next step -- really should not be necessary when using SimpleLogger\n",
    "    only_steps = interactions[interactions['interaction'] == 'step'].copy()\n",
    "    \n",
    "    #this section is all of the time formatting you're doing-- \n",
    "    #it's pretty redundant, and you can definitely cut some of it\n",
    "    \n",
    "    # The format of your datetime strings\n",
    "    datetime_format = '%H:%M:%S.%f'\n",
    "    # Convert 'startTime' to datetime objects\n",
    "    only_steps['startTime'] = pd.to_datetime(only_steps['startTime'], format=datetime_format)\n",
    "    #convert endTime too, just to make it not be weird and inconsistent\n",
    "    only_steps['endTime'] = pd.to_datetime(only_steps['endTime'], format=datetime_format)\n",
    "    positions['timeStamp'] = pd.to_datetime(positions['timeStamp'], format=datetime_format)\n",
    "    interactions['startTime'] = pd.to_datetime(interactions['startTime'], format=datetime_format)\n",
    "    interactions['endTime'] = pd.to_datetime(interactions['endTime'], format=datetime_format)\n",
    "    \n",
    "    # Initialize the 'currentStep', 'duration' columns\n",
    "    positions['currentStep'] = None\n",
    "    positions['duration'] = None\n",
    "    \n",
    "    \n",
    "    #...the hard part, where we match step numbers and durations from one dataframe to positions from the other\n",
    "    counter = 0 #number of errors we've encountered\n",
    "\n",
    "    #here, we use anti-patterns as aggresively as possible in order to make python behave more like C#\n",
    "    #it runs pretty slow\n",
    "    for positionIndex in range(positions.shape[0]): #for all positions\n",
    "        for stepIndex in range(only_steps.shape[0]): # for all steps\n",
    "            #check if timeStamp is after starttime\n",
    "            positionTimeStamp = positions.loc[positionIndex, 'timeStamp']\n",
    "            startTime = only_steps.iloc[stepIndex, 0]\n",
    "            startTime = pd.to_datetime(startTime) \n",
    "            if isinstance(positionTimeStamp, pd.Timestamp) and positionTimeStamp>startTime:\n",
    "                if positionTimeStamp>startTime:\n",
    "                    #time stamp is after start time.\n",
    "                    #check if it is also before end time\n",
    "                    endTime = only_steps.iloc[stepIndex,1]\n",
    "\n",
    "                    try:\n",
    "                        endTime = pd.to_datetime(endTime)\n",
    "                        # if this position data comes from a timestamp that is during this step...\n",
    "                        if isinstance(endTime, pd.Timestamp) and positionTimeStamp<endTime: \n",
    "                            #then set the 'currentStep' of this position to the correct step\n",
    "                            positions.loc[positionIndex, 'currentStep'] = only_steps.iloc[stepIndex, 4]\n",
    "                            #and set 'duration' to the duration of this step\n",
    "                            positions.loc[positionIndex, 'duration'] = only_steps.iloc[stepIndex, 2]\n",
    "                    except ValueError:\n",
    "                        counter +=1\n",
    "                else:\n",
    "                    print(\"position time stamp before start time\")\n",
    "                    print(positionTimeStamp)\n",
    "\n",
    "    print(\"Number of errors found in endTime parsing:\")\n",
    "    print(counter)\n",
    "    \n",
    "    #check that it worked...\n",
    "    #print(positions.loc[900])\n",
    "    \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d5863",
   "metadata": {},
   "source": [
    "# Make the Very Big Data Frame\n",
    "By calling the above function... so many times. Takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef8d5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "Number of errors found in endTime parsing:\n",
      "0\n",
      "done!\n",
      "number of rows in THE BIG DATA FRAME:\n",
      "(86159, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#P7 WAS RECORDED IN THE WRONG SCENE-- DO NOT INCLUDE\n",
    "\n",
    "files_to_process = [\n",
    "    ('P2/P2_positions.csv', 'P2/P2_interactions.csv', 1),\n",
    "    ('P3/P3_positions.csv', 'P3/P3_interactions.csv', 2),\n",
    "    ('P3/P3_positions2.csv', 'P3/P3_interactions2.csv', 3),\n",
    "    ('P4/P4_positions.csv', 'P4/P4_interactions.csv', 4),\n",
    "    ('P5/P5_positions.csv', 'P5/P5_interactions.csv', 5),\n",
    "    ('P6/P6_positions.csv', 'P6/P6_interactions.csv', 6),\n",
    "    ('P8/P8_positions.csv', 'P8/P8_interactions.csv', 8),\n",
    "    ('P9/P9_positions.csv', 'P9/P9_interactions.csv', 9),\n",
    "    ('P10/P10_positions.csv', 'P10/P10_interactions.csv', 10),\n",
    "    ('P11/P11_positions.csv', 'P11/P11_interactions.csv', 11),    \n",
    "    ('P12/P12_positions.csv', 'P12/P12_interactions.csv', 12),\n",
    "    ('P13/P13_positions.csv', 'P13/P13_interactions.csv', 13),\n",
    "    ('P16/P16_positions.csv', 'P16/P16_interactions.csv', 16),\n",
    "    ('P17/P17_positions.csv', 'P17/P17_interactions.csv', 17),\n",
    "    ('P18/P18_positions.csv', 'P18/P18_interactions.csv', 18),\n",
    "    ('P19/P19_positions.csv', 'P19/P19_interactions.csv', 19),\n",
    "    ('P20/P20_positions.csv', 'P20/P20_interactions.csv', 20),\n",
    "    ('P21/P21_positions.csv', 'P21/P21_interactions.csv', 21),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "processed_dfs = []  # List to store processed DataFrames\n",
    "\n",
    "for positions, interactions, participant_number in files_to_process:\n",
    "    processed_df = process_file(positions, interactions, participant_number)\n",
    "    processed_dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all processed DataFrames into one\n",
    "combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "\n",
    "print(\"done!\")\n",
    "print(\"number of rows in THE BIG DATA FRAME:\")\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1fed8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      timeStamp        headPosition              headEuler  \\\n",
      "0 1900-01-01 11:19:07.683963100  (-1.5: -0.1: 17.7)      (0.0: 180.0: 0.0)   \n",
      "1 1900-01-01 11:19:08.565464700   (-1.1: 1.9: 17.4)  (359.6: 170.2: 359.9)   \n",
      "2 1900-01-01 11:19:08.898467400   (-1.1: 1.9: 17.4)    (0.3: 170.6: 359.8)   \n",
      "3 1900-01-01 11:19:09.232968300   (-1.1: 1.9: 17.4)    (1.0: 171.5: 359.9)   \n",
      "4 1900-01-01 11:19:09.565469000   (-1.1: 1.9: 17.4)    (0.9: 172.5: 359.9)   \n",
      "\n",
      "               headQuat    leftHandPosition   rightHandPosition currentLeftGO  \\\n",
      "0  (0.0: 1.0: 0.0: 0.0)  (-1.5: -0.1: 17.7)  (-1.5: -0.1: 17.7)       INVALID   \n",
      "1  (0.0: 1.0: 0.0: 0.1)   (-1.6: 0.0: 16.6)   (-1.6: 0.0: 16.6)       INVALID   \n",
      "2  (0.0: 1.0: 0.0: 0.1)   (-1.6: 0.0: 16.6)   (-1.6: 0.0: 16.6)       INVALID   \n",
      "3  (0.0: 1.0: 0.0: 0.1)   (-1.6: 0.0: 16.6)   (-1.6: 0.0: 16.6)       INVALID   \n",
      "4  (0.0: 1.0: 0.0: 0.1)   (-1.6: 0.0: 16.6)   (-1.6: 0.0: 16.6)       INVALID   \n",
      "\n",
      "  currentRightGO                                     currentRayGeos  \\\n",
      "0        INVALID  Floor_01_10m_Prefab_01 (1) : Office_01a_2m_Wal...   \n",
      "1        INVALID  Forward Trigger : Office_01a_2m_Wall : Office_...   \n",
      "2        INVALID  Forward Trigger : Office_01a_2m_Wall : Office_...   \n",
      "3        INVALID  Forward Trigger : Office_01a_2m_Wall : Office_...   \n",
      "4        INVALID  Forward Trigger : Office_01a_2m_Wall : Office_...   \n",
      "\n",
      "     rayVoxelPosition  participantNumber currentStep duration  \n",
      "0  (-1.5: -0.1: 15.7)                  1        None     None  \n",
      "1   (-0.7: 1.9: 15.4)                  1        None     None  \n",
      "2   (-0.7: 1.9: 15.4)                  1        None     None  \n",
      "3   (-0.8: 1.8: 15.4)                  1        None     None  \n",
      "4   (-0.8: 1.8: 15.4)                  1        None     None  \n"
     ]
    }
   ],
   "source": [
    "# check that it worked...\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f585e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeStamp            1900-01-01 11:25:35.367872600\n",
      "currentStep                                   None\n",
      "duration                                      None\n",
      "participantNumber                                2\n",
      "headPosition                      (-2.2: 1.7: 7.8)\n",
      "rightHandPosition                 (-2.4: 1.4: 7.8)\n",
      "leftHandPosition                  (-2.4: 1.4: 7.7)\n",
      "Name: 7000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def simplify_df(df, columns):\n",
    "    return df[columns]\n",
    "\n",
    "smaller_df = create_smaller_dataframe(combined_df, ['timeStamp', 'currentStep', 'duration', 'participantNumber','headPosition', 'rightHandPosition', 'leftHandPosition'])\n",
    "\n",
    "print(smaller_df.loc[7000])  # Display the first few rows of the smaller DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0ffe5",
   "metadata": {},
   "source": [
    "# Section 2: Make Voxel Dataframes\n",
    "This section takes our position data, which there could be any quantity of, and turn it into one matrix of coordinates per tracked object per frame. Every voxel for which combined_df has data is associated with a DEPTH value. In this step, we abstract away from information about specific participants, or information about how much data is associated with each voxel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "057fe934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a second data frame, calculated from the big one, of just voxels, stepNumbers, objects, and struggle values.\n",
    "#one dataframe per tracked object\n",
    "#for efficiency reasons, it might eventually make sense to make a separate data frame for each step\n",
    "#but that sounds like it might make the files more annoying to work with\n",
    "\n",
    "#this takes ~5 seconds to run\n",
    "def create_voxel_df(column_name, df):\n",
    "    # Function to parse position string and convert to voxel coordinates\n",
    "    def parse_position_to_voxel(pos_str):\n",
    "        x, y, z = map(float, pos_str.strip('()').split(':'))\n",
    "        return x, y, z\n",
    "\n",
    "    # Apply the parsing and voxel function to the specified position data\n",
    "    df['voxel_x'], df['voxel_y'], df['voxel_z'] = zip(*df[column_name].apply(parse_position_to_voxel))\n",
    "\n",
    "    # Convert duration to a numerical value (total seconds)\n",
    "    df['duration_seconds'] = pd.to_timedelta(df['duration']).dt.total_seconds()\n",
    "\n",
    "    # Group by voxel coordinates and step number, then calculate the mean duration and count the rows\n",
    "    voxel_df = df.groupby(['voxel_x', 'voxel_y', 'voxel_z', 'currentStep']).agg(\n",
    "        struggleValue=('duration_seconds', 'mean'),\n",
    "        rowCount=('duration_seconds', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    voxel_df.rename(columns={'duration_seconds': 'struggleValue'}, inplace=True)\n",
    "\n",
    "    # Sort by step number\n",
    "    voxel_df.sort_values(by='currentStep', inplace=True)\n",
    "    \n",
    "    print(\"voxel head:\")\n",
    "    print(voxel_df.head())\n",
    "    print(\"voxel shape:\")\n",
    "    print(voxel_df.shape)\n",
    "\n",
    "    return voxel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904c9cf",
   "metadata": {},
   "source": [
    "## Make Voxel DataFrames\n",
    "One data frame per tracked object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe82377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel head:\n",
      "      voxel_x  voxel_y  voxel_z  currentStep  struggleValue  rowCount\n",
      "923       0.9      0.8     -3.1            0      15.690191         3\n",
      "327       0.6      1.1     -3.1            0       9.259005         4\n",
      "325       0.6      1.1     -3.2            0      20.782579         1\n",
      "324       0.6      1.1     -3.8            0       5.445603         1\n",
      "4077      1.3      0.9     -3.0            0      22.845098         2\n",
      "voxel shape:\n",
      "(5370, 6)\n",
      "voxel head:\n",
      "      voxel_x  voxel_y  voxel_z  currentStep  struggleValue  rowCount\n",
      "536       0.6      0.8     -3.3            0      20.782579         1\n",
      "3592      1.2      0.7     -3.0            0      21.476953         1\n",
      "4398      1.3      1.0     -2.8            0       9.581019         1\n",
      "225       0.3      1.2     -2.6            0      20.470017         1\n",
      "458       0.5      1.1     -3.9            0       5.445603         1\n",
      "voxel shape:\n",
      "(5112, 6)\n",
      "voxel head:\n",
      "      voxel_x  voxel_y  voxel_z  currentStep  struggleValue  rowCount\n",
      "0        -0.4      1.6     -2.7            0      20.470017         1\n",
      "206       0.5      1.7     -3.2            0      20.782579         1\n",
      "208       0.5      1.7     -2.9            0      31.634517         2\n",
      "210       0.5      1.7     -2.8            0      31.634517         2\n",
      "2008      1.0      1.7     -2.8            0      31.634517         2\n",
      "voxel shape:\n",
      "(3624, 6)\n"
     ]
    }
   ],
   "source": [
    "rightHand_df = create_voxel_df('rightHandPosition', combined_df)\n",
    "leftHand_df = create_voxel_df('leftHandPosition', combined_df)\n",
    "headPos_df = create_voxel_df('headPosition', combined_df)\n",
    "\n",
    "#save them to csv files\n",
    "rightHand_df.to_csv(\"rightHandVoxelVals.csv\")\n",
    "leftHand_df.to_csv(\"leftHandVoxelVals.csv\")\n",
    "headPos_df.to_csv(\"headPosVoxelVals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db969fa",
   "metadata": {},
   "source": [
    "# Section 3: Averages\n",
    "When we have no data for a voxel, we should return the average duration for the overall step (rather than 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ca32530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done! Here's the average duration dataframe:\n",
      "    currentStep  averageDuration\n",
      "0             0        16.917993\n",
      "1             1        31.883381\n",
      "2             2        21.184851\n",
      "3             3        48.474720\n",
      "4             4       125.149054\n",
      "5             5        47.282039\n",
      "6             6        32.069374\n",
      "7             7        59.709139\n",
      "8             8        14.358170\n",
      "9             9        17.338134\n",
      "10           10        26.171734\n",
      "11           11        11.046651\n",
      "12           12        76.970495\n",
      "13           13         6.477943\n",
      "14           25        35.506851\n",
      "15           26        69.298364\n",
      "16           27        34.435676\n",
      "17           28        35.327887\n",
      "18           29       103.530542\n",
      "19           30        60.309307\n",
      "20           31        29.562788\n",
      "21           32       207.833538\n",
      "22           33        42.554830\n",
      "23           34        31.826103\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_duration_per_step(df):\n",
    "    # Convert duration to a numerical value (total seconds)\n",
    "    df['duration_seconds'] = pd.to_timedelta(df['duration']).dt.total_seconds()\n",
    "    \n",
    "    #special for Varun-- get just the duration of steps on a participant by participant basis\n",
    "\n",
    "\n",
    "    # Group by participant number and 'currentStep', then calculate the average duration\n",
    "    step_duration_df = df.groupby(['participantNumber', 'currentStep'])['duration_seconds'].mean().reset_index()\n",
    "\n",
    "    \n",
    "    # Further group by 'currentStep' and calculate the overall average duration per step\n",
    "    overall_step_duration_df = step_duration_df.groupby('currentStep')['duration_seconds'].mean().reset_index()\n",
    "    overall_step_duration_df.rename(columns={'duration_seconds': 'averageDuration'}, inplace=True)\n",
    "    \n",
    "    print(\"done! Here's the average duration dataframe:\")\n",
    "    print(overall_step_duration_df)\n",
    "\n",
    "    return overall_step_duration_df\n",
    "\n",
    "average_struggle_df = calculate_average_duration_per_step(combined_df)\n",
    "average_struggle_df.to_csv(\"averageStepDuration.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5a5b1",
   "metadata": {},
   "source": [
    "# Section 4: Utilities\n",
    "Useful stuff, but not essential for getting data re-sorted and ready to be given to the Unity visualizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca949b",
   "metadata": {},
   "source": [
    "## a function for getting the DEPTH value for a specific step and set of voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd034f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinate of voxel, step, df of all struggle indexes for one tracked object, df of average duration for steps\n",
    "def get_depth_value(x, y, z, step, voxel_df, fallback_df):\n",
    "    # Query the DataFrame for the given coordinates and step number\n",
    "    matching_row = voxel_df[(voxel_df['voxel_x'] == x) & \n",
    "                            (voxel_df['voxel_y'] == y) & \n",
    "                            (voxel_df['voxel_z'] == z) & \n",
    "                            (voxel_df['currentStep'] == step)]\n",
    "    \n",
    "    # Check if the query returned a result\n",
    "    if not matching_row.empty:\n",
    "        # Return the struggle value\n",
    "        print(\"matching row is: \")\n",
    "        print(matching_row['struggleValue'].iloc[0])\n",
    "        print(\"based on this many data points: \")\n",
    "        print(matching_row['rowCount'])\n",
    "        return matching_row['struggleValue'].iloc[0]\n",
    "    else:\n",
    "        # Handle case where there is no matching voxel\n",
    "        print(\"No struggle value found for the following values of x, y, z, and step:\")\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print(z)\n",
    "        print(step)\n",
    "        print(\"Returning average duration for this step instead: \")\n",
    "        # Find and return the average duration for the given step\n",
    "        fallback_row = fallback_df[fallback_df['currentStep'] == step]\n",
    "        if not fallback_row.empty:\n",
    "            print(fallback_row['averageDuration'].iloc[0])\n",
    "            return fallback_row['averageDuration'].iloc[0]\n",
    "        else:\n",
    "            print(\"Something went wrong-- cannot get struggle value.\")\n",
    "            return None  # Or a default value as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
